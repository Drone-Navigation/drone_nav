<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <meta charset="utf-8">
  <meta name="description"
        content="DroneNav">
  <meta name="keywords" content="VATEX, RIS, Vision-Aware Text Features, Referring Image Segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AgriNav-Sim2Real: A Multi-Sensor Dataset for Drone/UGV Navigation in Greenhouses (Synthetic + Real)</title>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="css/bulma.min.css">
  <link rel="stylesheet" href="bulma-carousel.min.css">
  <link rel="stylesheet" href="css/bulma-slider.min.css">
  <link rel="stylesheet" href="css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="js/fontawesome.all.min.js"></script>
  <script src="js/bulma-carousel.min.js"></script>
  <script src="js/bulma-slider.min.js"></script>
  <script src="js/index.js"></script>

  <style>
    .abstract-container {
      animation: fadeIn 1s ease-in;
      background: linear-gradient(135deg, #f5f7fa 0%, #e8ecf1 100%);
      padding: 2rem;
      border-radius: 15px;
      box-shadow: 0 4px 15px rgba(0,0,0,0.1);
      margin: 2rem 0;
    }

    .highlight-box {
      background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
      padding: 1.5rem;
      margin: 2rem 0;
      border-left: 5px solid #4a90e2;
      border-radius: 8px;
      transition: transform 0.3s ease;
    }

    .highlight-box:hover {
      transform: translateY(-5px);
    }

    .feature-box {
      background: #fff;
      padding: 1.5rem;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
      transition: all 0.3s ease;
    }

    .feature-box:hover {
      transform: translateY(-5px);
      box-shadow: 0 6px 15px rgba(0,0,0,0.15);
    }

    .features-container {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1.5rem;
      margin: 2rem 0;
    }

    @media (max-width: 768px) {
      .features-container {
        grid-template-columns: 1fr;
      }
    }

    .object-feature {
      background: linear-gradient(135deg, #fff5f0 0%, #fff 100%);
      border-left: 4px solid #C55A11;
    }

    .context-feature {
      background: linear-gradient(135deg, #f0f5ff 0%, #fff 100%);
      border-left: 4px solid #0570C0;
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(20px); }
      to { opacity: 1; transform: translateY(0); }
    }
    .section {
      padding-top: 10px;
      padding-bottom: 10px;
      padding-left: 10px;
      padding-right: 10px;
    }
  </style>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-spaced is-1 publication-title"> AgriNav-Sim2Real: A Multi-Sensor Dataset for Drone/UGV Navigation in Greenhouses (Synthetic + Real)</h1>
          <!-- <h2 class="subtitle is-3" style="color: #ff3860; margin-bottom: 12px; margin-top: -12px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0,0,0,0.2); animation: fadeIn 1s ease-out;">paper in preparation 2025</h2> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/EvelynZhu88">Evelyn Zhu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/tuananh1007">Tuan-Anh Vu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/view/akshatpandya">Akshat Pandya</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/llamallamapresident">Russell Luo</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/structuresComp">M. Khalid Jawed</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Los Angeles</span>
            <span class="author-block"><sup>2</sup>Cruise</span>
          </div>
          <div class="is-size-6 publication-authors">
<!--             <span class="author-block"><sup>*</sup>Equal contribution</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/StructuresComp/drone-navigation.git"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link -->
              <span class="link-block">
                <a href="https://ucla.app.box.com/folder/336033645457?s=be2bwg0l6qg6p8mcfbr48e7u5yatfk5y"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-image"></i>
                  </span>
                  <span>Download Our Dataset</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <p align="center">
        <img src="images/teaser.png" alt="empty" width="500">
      </p>
      
      <h2 class="subtitle has-text-centered">
      </h2>
      <h2 class="subtitle has-text-centered">
        <br>
      </h2>
    </div>
  </div>
</section>


<section class="section hero">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 animate__animated animate__fadeIn">Abstract</h2>
        <div class="content has-text-justified">
          <div class="abstract-container">
            <p>
              We introduce <strong>AgriNav-Sim2Real</strong>, a large-scale dataset for <strong>greenhouse navigation</strong> that bridges synthetic (Unreal Engine + AirSim) and real (handheld/UGV/drone) captures.
              The <strong>synthetic split</strong> provides RGB, Depth, Semantic Segmentation, LiDAR, IMU, and GPS/pose data in a 3×5 connected-greenhouse with 10 canonical routes (loop, straight, zig-zag, in/out), rendered at a resolution of <strong>960×540 px</strong>.
              The <strong>real split</strong> offers ZED2i RGB-D, Alvium NIR, and IMU recordings across multiple farm sessions, with optional Insta360 360° context, captured at <strong>3840×2160 px</strong> resolution.
            </p>
            <p>
              In total, the dataset contains <strong>847,243 files</strong> (<strong>15 videos, 674.3 GB</strong>), organized with timestamp-based filenames shared across modalities for straightforward synchronization and consistent folder layout for loaders and baselines.
            </p>

            <p>
              We also establish a <strong>benchmark suite</strong> evaluating recent methods in <strong>object detection</strong> and <strong>semantic segmentation</strong> (e.g., <em>YOLOv8</em>, <em>Mask R-CNN</em>, <em>SegFormer</em>) to assess sim-to-real generalization across multi-sensor inputs (RGB, Depth, NIR).
            </p>

            <p>
              <strong>AgriNav-Sim2Real</strong> targets tasks in <strong>navigation and obstacle avoidance</strong>, <strong>depth estimation</strong>, <strong>semantic segmentation</strong>, <strong>cross-modal fusion (RGB-D/NIR)</strong>, and <strong>sim-to-real transfer</strong> (train synthetic → evaluate real).
            </p>
            <!-- Dataset Highlights (split into Synthetic and Real) -->
            <h2 class="title is-3 has-text-centered" style="margin-top: 2rem;">Dataset Highlights</h2>

            <!-- Synthetic Block -->
            <div class="highlight-box" style="margin-bottom: 1rem;">
              <div style="display:flex; align-items:center; gap:10px; margin-bottom:10px;">
                <i class="fas fa-robot" style="font-size:20px; color:#555;"></i>
                <span style="font-size:18px; font-weight:700;">Synthetic Dataset Highlight✨</span>
              </div>
              <p style="margin:0.5rem 0;">
                <strong>Modalities:</strong> RGB, Depth (PFM), Semantic Segmentation (uint8 masks), LiDAR (ASCII), IMU, GPS/pose.
              </p>
              <p style="margin:0.5rem 0;">
                <strong>Environment:</strong> 3×5 connected greenhouses with dynamic lighting, wind, clutter, and 10 route classes
                (Route #1–#10) rendered via Unreal Engine + AirSim.
              </p>
              <p style="margin:0.5rem 0;">
                <strong>Organization:</strong> Per-route folder structure with timestamp-based filenames shared across modalities;
                optional <code>scenes/</code> (for domain randomization) and <code>routes/</code> (for waypoints).
              </p>
              <p style="margin:0.5rem 0;">
                <strong>Use Cases:</strong> Synthetic data pretraining, sensor fusion benchmarking, 3D reconstruction,
                and sim-to-real transfer learning.
              </p>
            </div>

            <!-- Real Block -->
            <div class="highlight-box">
              <div style="display:flex; align-items:center; gap:10px; margin-bottom:10px;">
                <i class="fas fa-leaf" style="font-size:20px; color:#555;"></i>
                <span style="font-size:18px; font-weight:700;">Real Dataset Highlight✨</span>
              </div>
              <p style="margin:0.5rem 0;">
                <strong>Modalities:</strong> ZED2i RGB-D + IMU; Alvium 1800 U-501 NIR; (FLIR Lepton LWIR capable but not in this release);
                Insta360 X3 for 360° context.
              </p>
              <p style="margin:0.5rem 0;">
                <strong>Environment:</strong> Field recordings from commercial greenhouses and open-farm setups under varying lighting,
                weather, and plant species (strawberries, blueberries, blackberries).
              </p>
              <p style="margin:0.5rem 0;">
                <strong>Organization:</strong> Per-session folders organized by timestamp and sensor type (e.g., <code>zed2i/</code>, <code>nir/</code>, <code>imu/</code>),
                synchronized for multimodal processing.
              </p>
              <p style="margin:0.5rem 0;">
                <strong>Use Cases:</strong> Real-world validation of trained navigation policies, depth estimation, and
                cross-modal RGB↔NIR domain adaptation.
              </p>
            </div>

              </div>
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/-uGaBHqbBd0?si=bi82-hq265HClC77" 
                  frameborder="0" 
                  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                  allowfullscreen
                  style="width: 100%; aspect-ratio: 16/9;">
          </iframe>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset Overview</h2>
        
        <div class="content has-text-justified">
          <h3 class="title is-4">Synthetic Data</h3>
          <p>
            Engine & Sim: Unreal Engine + AirSim with a 3×5 connected-greenhouse map, dynamic lights, wind, and clutter.
          </p>
          
          <table align="center">
            <tr align="center">
              <td align="center">
                <img src="images/Greenhouse_setup_front.png" width="600"><br>
                <em>Front view</em>
              </td>
              <td align="center">
                <img src="images/Greenhouse_setup_side.png" width="530"><br>
                <em>Side view</em>
              </td>
            </tr>
          </table>
          
          <p align="center">
            <img src="images/Greenhouse_visual.gif" width="600" style="display:block; margin:0 auto;">
            <br>
            Demo video
          </p>

          <h4 class="title is-5">Canonical Routes</h4>
          <p align="center">
            <img src="images/Route_Plan.png" width="90%"><br>
            We collected 10 different routes in our simulation environment.
          </p>
          
          <h3 class="title is-4">Real Data</h3>
          <table align="center">
            <tr align="center">
              <td><img src="images/Farm_Left.jpg" width="300"><br><em>Farm (left)</em></td>
              <td><img src="images/Farm_Middle.jpg" width="300"><br><em>Farm (center)</em></td>
              <td><img src="images/Farm_Right.jpg" width="300"><br><em>Farm (right)</em></td>
            </tr>
            <tr align="center">
              <td><img src="images/farm_strawberries.jpg" width="300"><br><em>Strawberries</em></td>
              <td><img src="images/farm_blueberries.jpg" width="300"><br><em>Blueberries</em></td>
              <td><img src="images/farm_blackberries.jpg" width="300"><br><em>Blackberries</em></td>
            </tr>
          </table>

          <p align="center">
            <img src="images/insta_visual_cut.gif">
            <br>
            <a href="https://cloud-va.insta360.com/share/va/2a8h819p6D9s2U7k1172661248/player?mediaId=288041035899080704">
              <span>You can view a 360 view of the Farm at here</span>
            </a>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3 has-text-centered">Benchmark</h2>
          <p>
            We evaluated the <strong>AgriNav-Sim2Real</strong> dataset using several recent deep-learning frameworks for
            <strong>object detection</strong> and <strong>semantic segmentation</strong>.
            Our benchmark focuses on assessing cross-modal generalization between synthetic and real data splits.
            The evaluation includes representative architectures such as <em>YOLOv8</em>, <em>Mask R-CNN</em>,
            and <em>SegFormer</em>, with metrics reported in mAP, IoU, and F1-score across greenhouse environments.
          </p>

          <p>
            These baselines serve as references for sim-to-real performance and highlight the challenges
            of domain adaptation under multi-sensor inputs (RGB, Depth, and NIR).
          </p>

          <div style="
            display: inline-flex;
            align-items: center;
            background: linear-gradient(135deg, #f5f7fa 0%, #e8ecf1 100%);
            border: 1px solid #d0d7de;
            border-radius: 8px;
            padding: 10px 16px;
            margin-top: 1.5rem;
            font-weight: 600;
            color: #555;">
            <span>Ongoing Work — To Be Updated</span>
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section" id="acknowledgements">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">Acknowledgements</h2>
          <p>
            This project was funded by the <strong>Department of Pesticide Regulation</strong>.  
            The contents may not necessarily reflect the official views or policies of the State of California.
          </p>
    </div>
  </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="content">
          <h2 class="title is-3">Citation</h2>
          <pre><code>@inproceedings{zhu2025drone,
title={AgriNav-Sim2Real: A Multi-Sensor Dataset for Drone/UGV Navigation in Greenhouses (Synthetic + Real)},
author={Evelyn Zhu, Tuan-Anh Vu, Akshat Pandya, Russell Luo, M. Khalid Jawed},
booktitle={xxx},
year={2025}
}</code></pre>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="license">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="content">
          <h2 class="title is-3">License</h2>
          <p>
            Our <strong>AgriNav-Sim2Real</strong> dataset is made available for <strong>non-commercial purposes only</strong>.
          </p>
          <ul>
            <li>You will not, directly or indirectly, reproduce, use, or convey the dataset or any content, or any work product or data derived therefrom, for commercial purposes.</li>
            <li>This code is for <strong>academic communication only</strong> and not for commercial purposes. If you wish to use it for commercial applications, please contact the authors.</li>
          </ul>

          <p>
            Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
          </p>
          <ul>
            <li>Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.</li>
            <li>Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.</li>
          </ul>

          <p style="font-size: 0.95em; color: #555; margin-top: 1rem;">
            THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
            IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
            HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

</body>
</html>
