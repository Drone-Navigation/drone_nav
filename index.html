<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <meta charset="utf-8">
  <meta name="description"
        content="DroneNav">
  <meta name="keywords" content="VATEX, RIS, Vision-Aware Text Features, Referring Image Segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AgriNav-Sim2Real: A Multi-Sensor Dataset for Drone/UGV Navigation in Greenhouses (Synthetic + Real)</title>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="css/bulma.min.css">
  <link rel="stylesheet" href="bulma-carousel.min.css">
  <link rel="stylesheet" href="css/bulma-slider.min.css">
  <link rel="stylesheet" href="css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="js/fontawesome.all.min.js"></script>
  <script src="js/bulma-carousel.min.js"></script>
  <script src="js/bulma-slider.min.js"></script>
  <script src="js/index.js"></script>

  <style>
    .abstract-container {
      animation: fadeIn 1s ease-in;
      background: linear-gradient(135deg, #f5f7fa 0%, #e8ecf1 100%);
      padding: 2rem;
      border-radius: 15px;
      box-shadow: 0 4px 15px rgba(0,0,0,0.1);
      margin: 2rem 0;
    }

    .highlight-box {
      background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
      padding: 1.5rem;
      margin: 2rem 0;
      border-left: 5px solid #4a90e2;
      border-radius: 8px;
      transition: transform 0.3s ease;
    }

    .highlight-box:hover {
      transform: translateY(-5px);
    }

    .feature-box {
      background: #fff;
      padding: 1.5rem;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
      transition: all 0.3s ease;
    }

    .feature-box:hover {
      transform: translateY(-5px);
      box-shadow: 0 6px 15px rgba(0,0,0,0.15);
    }

    .features-container {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1.5rem;
      margin: 2rem 0;
    }

    @media (max-width: 768px) {
      .features-container {
        grid-template-columns: 1fr;
      }
    }

    .object-feature {
      background: linear-gradient(135deg, #fff5f0 0%, #fff 100%);
      border-left: 4px solid #C55A11;
    }

    .context-feature {
      background: linear-gradient(135deg, #f0f5ff 0%, #fff 100%);
      border-left: 4px solid #0570C0;
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(20px); }
      to { opacity: 1; transform: translateY(0); }
    }
  </style>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-spaced is-1 publication-title"> AgriNav-Sim2Real: A Multi-Sensor Dataset for Drone/UGV Navigation in Greenhouses (Synthetic + Real)</h1>
          <!-- <h2 class="subtitle is-3" style="color: #ff3860; margin-bottom: 12px; margin-top: -12px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0,0,0,0.2); animation: fadeIn 1s ease-out;">paper in preparation 2025</h2> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/EvelynZhu88">Evelyn Zhu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/tuananh1007">Tuan-Anh Vu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="/">Akshat Pandya</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/llamallamapresident">Russel Luo</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/structuresComp">M. Khalid Jawed</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Los Angeles</span>
            <span class="author-block"><sup>2</sup>The Hong Kong University of Science and Technology</span>
            <span class="author-block"><sup>3</sup>Cruise</span>
          </div>
          <div class="is-size-6 publication-authors">
<!--             <span class="author-block"><sup>*</sup>Equal contribution</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/StructuresComp/drone-navigation.git"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link -->
              <span class="link-block">
                <a href="https://ucla.app.box.com/folder/336033645457?s=be2bwg0l6qg6p8mcfbr48e7u5yatfk5y"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-image"></i>
                  </span>
                  <span>Download Our Dataset</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <p align="center">
        <img src="images/teaser.png" alt="empty" width="500">
      </p>
      
      <h2 class="subtitle has-text-centered">
      </h2>
      <h2 class="subtitle has-text-centered">
        <br>
      </h2>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 animate__animated animate__fadeIn">Abstract</h2>
        <div class="content has-text-justified">
          <div class="abstract-container">
            <p>
              We introduce AgriNav-Sim2Real, a dataset for <strong>greenhouse navigation</strong> that combines synthetic (Unreal Engine + AirSim) and real (handheld/UGV/drone) captures. The synthetic split provides RGB, Depth, Semantic Segmentation, LiDAR, IMU, and GPS/pose in a 3×5 connected-greenhouse with 10 canonical routes (loop, straight, zig-zag, in/out). The real split offers ZED2i RGB-D, Alvium NIR, and IMU across multiple farm sessions, with optional Insta360 360° context. Data are organized with timestamp-based filenames shared across modalities for straightforward synchronization and a consistent folder layout for loaders and baselines. <strong>We target tasks in navigation/obstacle avoidance, depth estimation, semantic segmentation, cross-modal fusion (RGB-D/NIR), and sim-to-real transfer (train synthetic → evaluate real)</strong>.
            </p>

            <div class="highlight-box">
              <p style="font-weight: bold; color: #333; font-size: 1.2em; margin: 0;">
                <p>
                  <span style="font-size:24px; font-weight:bold;">Dataset Highlights:</span>
                </p>
              <p>
                <strong>Modalities (Synthetic):</strong> RGB, Depth (PFM), Semantic Segmentation (uint8 masks), LiDAR (ASCII), IMU, GPS/pose. <br>

<strong>Modalities (Real):</strong> ZED2i RGB-D + IMU; Alvium 1800 U-501 NIR; (FLIR Lepton LWIR capable but not in this release); Insta360 X3 for 360° context.<br>

<strong>Environment:</strong> 3×5 connected greenhouses with dynamic lights, wind, clutter, and 10 route classes (Route #1…#10).<br>

<strong>Organization:</strong> Per-route/per-session trees; timestamp-based filenames shared across modalities; optional scenes/ (domain randomization), routes/ (waypoints).<br>
<strong>Use cases:</strong> Navigation & obstacle avoidance; depth & segmentation; RGB↔NIR fusion; domain adaptation & transfer.<br>
              </p>
              </p>
            </div>
              </div>
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
<!--         <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/-uGaBHqbBd0?si=bi82-hq265HClC77" 
                  frameborder="0" 
                  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                  allowfullscreen
                  style="width: 100%; aspect-ratio: 16/9;"> -->
          </iframe>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset Overview</h2>
        
        <div class="content has-text-justified">
          <h3 class="title is-4">Synthetic Data</h3>
          <p>
            Engine & Sim: Unreal Engine + AirSim with a 3×5 connected-greenhouse map, dynamic lights, wind, and clutter.
          </p>
          
          <table align="center">
            <tr align="center">
              <td align="center">
                <img src="images/Greenhouse_setup_front.png" width="600"><br>
                <em>Front view</em>
              </td>
              <td align="center">
                <img src="images/Greenhouse_setup_side.png" width="530"><br>
                <em>Side view</em>
              </td>
            </tr>
          </table>
          
          <p align="center">
            <img src="images/Greenhouse_visual.gif" width="600" style="display:block; margin:0 auto;">
            <br>
            Demo video
          </p>

          <h4 class="title is-5">Canonical Routes</h4>
          <p align="center">
            <img src="images/Route_Plan.png" width="90%"><br>
            We collected 10 different routes in our simulation environment.
          </p>
          
          <h3 class="title is-4">Real Data</h3>
          <table align="center">
            <tr align="center">
              <td><img src="images/Farm_Left.jpg" width="300"><br><em>Farm (left)</em></td>
              <td><img src="images/Farm_Middle.jpg" width="300"><br><em>Farm (center)</em></td>
              <td><img src="images/Farm_Right.jpg" width="300"><br><em>Farm (right)</em></td>
            </tr>
            <tr align="center">
              <td><img src="images/farm_strawberries.jpg" width="300"><br><em>Strawberries</em></td>
              <td><img src="images/farm_blueberries.jpg" width="300"><br><em>Blueberries</em></td>
              <td><img src="images/farm_blackberries.jpg" width="300"><br><em>Blackberries</em></td>
            </tr>
          </table>

          <p align="center">
            <img src="images/insta_visual_cut.gif">
            <br>
            <a href="https://cloud-va.insta360.com/share/va/2a8h819p6D9s2U7k1172661248/player?mediaId=288041035899080704">
              <span>You can view a 360 view of the Farm at here</span>
            </a>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3 has-text-centered">Benchmark</h2>
          <p>
            We evaluated the <strong>AgriNav-Sim2Real</strong> dataset using several recent deep-learning frameworks for
            <strong>object detection</strong> and <strong>semantic segmentation</strong>.
            Our benchmark focuses on assessing cross-modal generalization between synthetic and real data splits.
            The evaluation includes representative architectures such as <em>YOLOv8</em>, <em>Mask R-CNN</em>,
            and <em>SegFormer</em>, with metrics reported in mAP, IoU, and F1-score across greenhouse environments.
          </p>

          <p>
            These baselines serve as references for sim-to-real performance and highlight the challenges
            of domain adaptation under multi-sensor inputs (RGB, Depth, and NIR).
          </p>

          <div style="
            display: inline-flex;
            align-items: center;
            background: linear-gradient(135deg, #f5f7fa 0%, #e8ecf1 100%);
            border: 1px solid #d0d7de;
            border-radius: 8px;
            padding: 10px 16px;
            margin-top: 1.5rem;
            font-weight: 600;
            color: #555;">
            <span>Ongoing Work — To Be Updated</span>
        </div>

      </div>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
  <div class="columns is-centered">
    <h2 class="title">Citation</h2>
    <pre><code>@inproceedings{zhu2025drone,
title={fill title here},
author={fill author list here},
booktitle={xxx},
year={2025}
}
</code></pre>
</div>
</div>
</section>

<section class="section" id="license">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">License</h2>
          <p>
            Our <strong>AgriNav-Sim2Real</strong> dataset is made available for <strong>non-commercial purposes only</strong>.
          </p>
          <p>
            You will not, directly or indirectly, reproduce, use, or convey the dataset or any content, or any work product or data derived therefrom, for commercial purposes.
          </p>
          <p>
            This code is for <strong>academic communication only</strong> and not for commercial purposes. If you wish to use it for commercial applications, please contact the authors.
          </p>

          <p>
            Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
          </p>
          <ul style="margin-left: 1.5rem; text-align: left;">
            <li>Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.</li>
            <li>Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.</li>
          </ul>

          <p style="font-size: 0.95em; color: #555; margin-top: 1rem;">
            THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
            IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
            HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
          </p>
      </div>
    </div>
  </div>
</section>


<section class="section" id="acknowledgements">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">Acknowledgements</h2>
          <p>
            This project was funded by the <strong>Department of Pesticide Regulation</strong>.  
            The contents may not necessarily reflect the official views or policies of the State of California.
          </p>
    </div>
  </div>
  </div>
</section>


</body>
</html>
